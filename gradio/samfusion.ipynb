{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.ones((300, 300, 3)) * 200\n",
    "# mask = mask[0, :, :]\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.fromarray(np.uint8(mask))\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DDIMScheduler, StableDiffusionInpaintPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=512x512>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(\"/home/docker_current/samfusion/mask.png\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)p16/model_index.json: 100%|██████████| 550/550 [00:00<00:00, 1.16MB/s]\n",
      "vae/diffusion_pytorch_model.safetensors not found\n",
      "Downloading (…)rocessor_config.json: 100%|██████████| 342/342 [00:00<00:00, 316kB/s]\n",
      "Downloading (…)cheduler_config.json: 100%|██████████| 287/287 [00:00<00:00, 480kB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 472/472 [00:00<00:00, 77.8kB/s]\n",
      "Downloading (…)_encoder/config.json: 100%|██████████| 635/635 [00:00<00:00, 201kB/s]\n",
      "\n",
      "\n",
      "Fetching 13 files:  31%|███       | 4/13 [00:00<00:01,  5.13it/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 821/821 [00:00<00:00, 2.18MB/s]\n",
      "\n",
      "Downloading (…)6e5/unet/config.json: 100%|██████████| 810/810 [00:00<00:00, 1.35MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Downloading (…)66e5/vae/config.json: 100%|██████████| 613/613 [00:00<00:00, 3.95MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)tokenizer/merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 1.14MB/s]\n",
      "Downloading (…)tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:00<00:00, 2.43MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "Fetching 13 files:  31%|███       | 4/13 [00:16<00:01,  5.13it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "Downloading (…)on_pytorch_model.bin: 100%|██████████| 167M/167M [03:16<00:00, 851kB/s] \n",
      "\n",
      "\u001b[A\n",
      "Downloading pytorch_model.bin: 100%|██████████| 246M/246M [03:24<00:00, 1.21MB/s]\n",
      "Downloading (…)on_pytorch_model.bin: 100%|██████████| 1.72G/1.72G [10:10<00:00, 2.81MB/s]\n",
      "Fetching 13 files: 100%|██████████| 13/13 [10:12<00:00, 47.11s/it]\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:11<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-inpainting\",\n",
    "    requires_safety_checker=False,\n",
    "    safety_checker=None,\n",
    "    revision=\"fp16\",\n",
    "    torch_dtype=torch.float16,\n",
    ").to(device)\n",
    "\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "\n",
    "MODEL_DICT = dict(\n",
    "    vit_h='https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth',  # yapf: disable  # noqa\n",
    "    vit_l='https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth',  # yapf: disable  # noqa\n",
    "    vit_b='https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth',  # yapf: disable  # noqa\n",
    ")\n",
    "\n",
    "\n",
    "def show_mask(mask: np.ndarray,\n",
    "              image: np.ndarray,\n",
    "              random_color: bool = False) -> np.ndarray:\n",
    "    \"\"\"Visualize a mask on top of an image.\n",
    "\n",
    "    Args:\n",
    "        mask (np.ndarray): A 2D array of shape (H, W).\n",
    "        image (np.ndarray): A 3D array of shape (H, W, 3).\n",
    "        random_color (bool): Whether to use a random color for the mask.\n",
    "    Returns:\n",
    "        np.ndarray: A 3D array of shape (H, W, 3) with the mask\n",
    "        visualized on top of the image.\n",
    "    \"\"\"\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3)], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1) * 255\n",
    "\n",
    "    image = cv2.addWeighted(image, 0.7, mask_image.astype('uint8'), 0.3, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def show_points(coords: np.ndarray, labels: np.ndarray,\n",
    "                image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Visualize points on top of an image.\n",
    "\n",
    "    Args:\n",
    "        coords (np.ndarray): A 2D array of shape (N, 2).\n",
    "        labels (np.ndarray): A 1D array of shape (N,).\n",
    "        image (np.ndarray): A 3D array of shape (H, W, 3).\n",
    "    Returns:\n",
    "        np.ndarray: A 3D array of shape (H, W, 3) with the points\n",
    "        visualized on top of the image.\n",
    "    \"\"\"\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    for p in pos_points:\n",
    "        image = cv2.circle(\n",
    "            image, p.astype(int), radius=5, color=(0, 255, 0), thickness=-1)\n",
    "    for p in neg_points:\n",
    "        image = cv2.circle(\n",
    "            image, p.astype(int), radius=5, color=(255, 0, 0), thickness=-1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def setup_model() -> SamPredictor:\n",
    "    \"\"\"Setup the model and predictor.\n",
    "\n",
    "    Returns:\n",
    "        SamPredictor: The predictor.\n",
    "    \"\"\"\n",
    "\n",
    "    model_type = 'vit_b'\n",
    "    device = 'cuda'\n",
    "\n",
    "    sam = sam_model_registry[model_type]()\n",
    "    sam.load_state_dict(torch.utils.model_zoo.load_url(MODEL_DICT[model_type]))\n",
    "    sam.half()\n",
    "    sam.to(device=device)\n",
    "\n",
    "    predictor = SamPredictor(sam)\n",
    "\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = setup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%blocks\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    # Define the UI\n",
    "    mask_level = gr.Slider(minimum=0, maximum=2, value=1, step=1,\\\n",
    "                           label='Masking level',\n",
    "                           info='(Whole - Part - Subpart) level')\n",
    "    # with gr.Row():\n",
    "    input_img = gr.Image(label='Input')\n",
    "    output_img = gr.Image(label='Selected Segment')\n",
    "\n",
    "    is_positive_box = gr.Checkbox(value=True, label='Positive point')\n",
    "    reset = gr.Button('Reset Points')\n",
    "\n",
    "    # Define the logic\n",
    "    saved_points = []\n",
    "    saved_labels = []\n",
    "\n",
    "    def set_image(img) -> None:\n",
    "        \"\"\"Set the image for the predictor.\"\"\"\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictor.set_image(img)\n",
    "\n",
    "    def segment_anything(img, mask_level: int, is_positive: bool,\n",
    "                         evt: gr.SelectData):\n",
    "        \"\"\"Segment the selected region.\"\"\"\n",
    "        mask_level = 2 - mask_level\n",
    "        saved_points.append([evt.index[0], evt.index[1]])\n",
    "        saved_labels.append(1 if is_positive else 0)\n",
    "        input_point = np.array(saved_points)\n",
    "        input_label = np.array(saved_labels)\n",
    "\n",
    "        # Predict the mask\n",
    "        with torch.cuda.amp.autocast():\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=input_point,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=True,\n",
    "            )\n",
    "        # mask has a shape of [3, h, w]\n",
    "        masks = masks[mask_level:mask_level + 1, ...]\n",
    "\n",
    "        # Visualize the mask\n",
    "        res = show_mask(masks, img)\n",
    "        # Visualize the points\n",
    "        res = show_points(input_point, input_label, res)\n",
    "        return res\n",
    "\n",
    "    def reset_points() -> None:\n",
    "        \"\"\"Reset the points.\"\"\"\n",
    "        global saved_points\n",
    "        global saved_labels\n",
    "        saved_points = []\n",
    "        saved_labels = []\n",
    "\n",
    "    # Connect the UI and logic\n",
    "    input_img.upload(set_image, [input_img])\n",
    "    input_img.select(segment_anything,\n",
    "                     [input_img, mask_level, is_positive_box], output_img)\n",
    "    reset.click(reset_points)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
